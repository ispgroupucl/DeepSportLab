{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seven-costa",
   "metadata": {},
   "source": [
    "# ROC on openpifpaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "japanese-repository",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/import/home/gva/poseestimation_emb/openpifpaf/visualizer/base.py:12: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"Oranges\"))\n",
      "  matplotlib.cm.get_cmap('Oranges').set_bad('white', alpha=0.5)\n",
      "/import/home/gva/poseestimation_emb/openpifpaf/visualizer/base.py:13: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"Blues\"))\n",
      "  matplotlib.cm.get_cmap('Blues').set_bad('white', alpha=0.5)\n",
      "/import/home/gva/poseestimation_emb/openpifpaf/visualizer/base.py:14: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"Greens\"))\n",
      "  matplotlib.cm.get_cmap('Greens').set_bad('white', alpha=0.5)\n"
     ]
    }
   ],
   "source": [
    "from mlworkflow import PickledDataset, TransformedDataset\n",
    "from dataset_utilities.ds.instants_dataset import ExtractViewData, ViewCropperTransform\n",
    "\n",
    "from openpifpaf.datasets.deepsport import AddBallSegmentationTargetViewFactory, AddBallPositionFactory\n",
    "\n",
    "ds = PickledDataset(\"/scratch/gva/views_camera_with_ball2.pickle\")\n",
    "\n",
    "shape = (800,600)\n",
    "\n",
    "ds = TransformedDataset(ds, [\n",
    "    ViewCropperTransform(def_min=30, def_max=80, output_shape=shape),\n",
    "    ExtractViewData(AddBallPositionFactory(), AddBallSegmentationTargetViewFactory()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "isolated-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "keys = list(PickledDataset(\"/scratch/gva/camera_views_with_human_masks.pickle\").keys.all())\n",
    "random.seed(0)\n",
    "random.shuffle(keys)\n",
    "validation_set_size_pc = 15\n",
    "lim = len(keys)*validation_set_size_pc//100\n",
    "training_keys = keys[lim:]\n",
    "validation_keys = keys[:lim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modern-liquid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "1394\n",
      "286\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_keys))\n",
    "validation_keys = [k for k in ds.yield_keys() if k not in training_keys]\n",
    "print(len(validation_keys))\n",
    "print(len(training_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adopted-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tf_layers import AvoidLocalEqualities, PeakLocalMax, ComputeElementaryMetrics\n",
    "class ChunkProcessor:\n",
    "    pass\n",
    "\n",
    "class CastFloat(ChunkProcessor):\n",
    "    def __init__(self, tensor_name):\n",
    "        self.tensor_name = [tensor_name] if isinstance(tensor_name, str) else tensor_name\n",
    "    def __call__(self, chunk):\n",
    "        for tensor_name in self.tensor_name:\n",
    "            if tensor_name in chunk:\n",
    "                chunk[tensor_name] = tf.cast(chunk[tensor_name], tf.float32)\n",
    "class Normalize(ChunkProcessor):\n",
    "    def __init__(self, tensor_name):\n",
    "        self.tensor_name = tensor_name\n",
    "    def __call__(self, chunk):\n",
    "        assert chunk[self.tensor_name].dtype == tf.float32\n",
    "        chunk[self.tensor_name] = chunk[self.tensor_name]/255\n",
    "class ComputeKeypointsDetectionAccuracy(ChunkProcessor):\n",
    "    def __init__(self, non_max_suppression_pool_size=50, threshold=0.5, target_enlargment_size=10):\n",
    "        thresholds = threshold if isinstance(threshold, np.ndarray) else np.array([threshold])\n",
    "        assert len(thresholds.shape) == 1, \"'threshold' argument should be 1D-array (a scalar is also accepted).\"\n",
    "\n",
    "        self.avoid_local_eq = AvoidLocalEqualities()\n",
    "        self.peak_local_max = PeakLocalMax(min_distance=non_max_suppression_pool_size//2, thresholds=thresholds)\n",
    "        self.enlarge_target = tf.keras.layers.MaxPool2D(target_enlargment_size, strides=1, padding=\"same\")\n",
    "        self.compute_metric = ComputeElementaryMetrics()\n",
    "\n",
    "    def __call__(self, chunk):\n",
    "        batch_target = tf.cast(chunk[\"batch_target\"], tf.float32)\n",
    "        batch_target = batch_target if len(batch_target.shape) == 4 else batch_target[...,tf.newaxis]\n",
    "        batch_output = chunk[\"batch_heatmap\"]\n",
    "        batch_output = batch_output if len(batch_output.shape) == 4 else batch_output[...,tf.newaxis]\n",
    "\n",
    "        batch_output = self.avoid_local_eq(batch_output)\n",
    "        batch_hitmap = self.peak_local_max(batch_output)\n",
    "        batch_hitmap = tf.cast(batch_hitmap, tf.int32)\n",
    "        chunk[\"batch_hitmap\"] = tf.squeeze(batch_hitmap)\n",
    "        batch_target = self.enlarge_target(batch_target)\n",
    "        batch_target = tf.cast(batch_target, tf.int32)[..., tf.newaxis]\n",
    "\n",
    "        batch_metric = self.compute_metric(batch_hitmap=batch_hitmap, batch_target=batch_target)\n",
    "        chunk[\"batch_TP\"] = tf.squeeze(batch_metric[\"batch_TP\"])\n",
    "        chunk[\"batch_FP\"] = tf.squeeze(batch_metric[\"batch_FP\"])\n",
    "        chunk[\"batch_TN\"] = tf.squeeze(batch_metric[\"batch_TN\"])\n",
    "        chunk[\"batch_FN\"] = tf.squeeze(batch_metric[\"batch_FN\"])\n",
    "\n",
    "        \n",
    "chunk = {}\n",
    "chunk[\"batch_heatmap\"] = tf.keras.Input(dtype=tf.uint8, shape=(shape[1], shape[0]), name=\"batch_heatmap\")\n",
    "chunk[\"batch_target\"] = tf.keras.Input(dtype=tf.uint8, shape=(shape[1], shape[0]), name=\"batch_target\")\n",
    "inputs = dict(chunk) # makes a copy\n",
    "\n",
    "thresholds = np.array([])\n",
    "n_points = 21\n",
    "chunk_processors = [\n",
    "    CastFloat([\"batch_heatmap\", \"batch_target\"]),\n",
    "    Normalize(\"batch_heatmap\"),\n",
    "    ComputeKeypointsDetectionAccuracy(non_max_suppression_pool_size=20, threshold=np.linspace(0,1,n_points)),\n",
    "]\n",
    "for cp in chunk_processors:\n",
    "    cp(chunk)\n",
    "\n",
    "outputs = {k:chunk[k] for k in chunk if k in [\"batch_TP\", \"batch_TN\", \"batch_FP\", \"batch_FN\"]}\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "played-suicide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd406d10786e41f59d1ced23f35f1b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4aeecba7a5a4da9a8df3fe85f8ae67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openpifpaf.predict:neural network device: cuda\n",
      "DEBUG:openpifpaf.network.heads:cif = [0], caf = []\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2c4d63da04ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;34m\"--debug-images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--debug-cif-c\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--debug\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         ]\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/gva/test.accumulated.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mresult\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"batch_heatmap\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch_target\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/import/home/gva/poseestimation_emb/openpifpaf/predict.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mpreprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/import/home/gva/poseestimation_emb/openpifpaf/predict.py\u001b[0m in \u001b[0;36mprocessor_factory\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mmodel_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactory_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;31m# print('Head nets')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# print(model.head_nets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from openpifpaf.predict import main\n",
    "import sys\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import Output\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "output = Output()\n",
    "display.display(output)\n",
    "\n",
    "#weights_file = \"shufflenetv2k16w-210225-164102-ball-edge501.pkl.epoch150\" # trained on small dataset\n",
    "#weights_file = \"shufflenetv2k16w-210308-164747-ball-edge501.pkl.epoch150\" # trained on full dataset\n",
    "#weights_file = \"shufflenetv2k16-210309-153430-ball-edge501.pkl.epoch200\" # trained on small dataset with fixed seed\n",
    "weights_file = \"shufflenetv2k16-210309-220522-ball.pkl.epoch499\" # trained on small dataset with fixed seed\n",
    "result = {}\n",
    "for set_name in [\"training_keys\", \"validation_keys\"]:\n",
    "    resul = result[set_name] = {}\n",
    "    resul[\"TP\"] = np.zeros(n_points, np.int32)\n",
    "    resul[\"FP\"] = np.zeros(n_points, np.int32)\n",
    "    resul[\"TN\"] = np.zeros(n_points, np.int32)\n",
    "    resul[\"FN\"] = np.zeros(n_points, np.int32)\n",
    "    for key in tqdm(training_keys):\n",
    "        data = ds.query_item(key)\n",
    "        filename = \"/home/gva/test.png\"\n",
    "        imageio.imwrite(filename, data[\"input_image\"])\n",
    "        sys.argv = [\n",
    "            \"aue\",\n",
    "            filename,\n",
    "            \"--checkpoint\", f\"/home/gva/poseestimation_emb/results/{weights_file}\",\n",
    "            \"--image-output\",\n",
    "            \"--debug-images\", \"--debug-cif-c\", \"--debug\"\n",
    "        ]\n",
    "        main()\n",
    "        heatmap = imageio.imread(\"/home/gva/test.accumulated.png\")\n",
    "        result  = model({\"batch_heatmap\": heatmap[np.newaxis], \"batch_target\": data[\"mask\"][np.newaxis]})\n",
    "        resul[\"TP\"] += result[\"batch_TP\"].numpy()\n",
    "        resul[\"FP\"] += result[\"batch_FP\"].numpy()\n",
    "        resul[\"TN\"] += result[\"batch_TN\"].numpy()\n",
    "        resul[\"FN\"] += result[\"batch_FN\"].numpy()\n",
    "        with output:\n",
    "            fig = plt.figure()\n",
    "            display.clear_output(wait=True)\n",
    "            x = resul[\"FP\"]/(resul[\"FP\"]+resul[\"TN\"])\n",
    "            y = resul[\"TP\"]/(resul[\"TP\"]+resul[\"FN\"])\n",
    "            ax = fig.gca()\n",
    "            \n",
    "            index = 10\n",
    "            \n",
    "            ax.plot(x,y, linestyle=\"-\", linewidth=1, markersize=5, marker=\".\", label=set_name)\n",
    "            ax.plot(x[index], y[index], markersize=10, marker=\".\", color=\"green\")\n",
    "            ax.text(x[index]+0.05, y[index]-0.05, \"threshold={}\".format(np.linspace(0,1,n_points)[index]), color=\"green\")\n",
    "            ax.set_xlabel(\"FP rate\")\n",
    "            ax.set_ylabel(\"TP rate\")\n",
    "            ax.axis(\"equal\")\n",
    "            ax.set_xlim([0,1])\n",
    "            ax.set_ylim([0,1])\n",
    "            ax.set_box_aspect(1)\n",
    "            ax.set_title(f\"ROC ball detection from PIFPAF\")\n",
    "            ax.legend()\n",
    "            \n",
    "            display.display(fig)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "for name in [\"training_set\", \"validation_set\"]:\n",
    "    d = eval(name)\n",
    "    x = d[\"FP\"]/(d[\"FP\"]+d[\"TN\"])\n",
    "    y = d[\"TP\"]/(d[\"TP\"]+d[\"FN\"])\n",
    "    index = 10\n",
    "    ax.plot(x,y, linestyle=\"-\", linewidth=1, markersize=5, marker=\".\", label=name)\n",
    "    ax.plot(x[index], y[index], markersize=10, marker=\".\", color=\"green\")\n",
    "    ax.text(x[index]+0.05, y[index]-0.05, \"threshold={}\".format(np.linspace(0,1,n_points)[index]), color=\"green\")\n",
    "    ax.set_xlabel(\"FP rate\")\n",
    "    ax.set_ylabel(\"TP rate\")\n",
    "    ax.axis(\"equal\")\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_box_aspect(1)\n",
    "    ax.set_title(f\"ROC ball detection from PIFPAF\")\n",
    "    ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-going",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-offense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-greensboro",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
